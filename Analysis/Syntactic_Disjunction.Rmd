---
title: "Syntactic Disjunction"
author: "Casey D. Felton"
date: '2023-03-28'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load required libraries
```{r, include= FALSE}
library('tidyverse')
library('ggplot2')
library('lme4')
library('lmerTest')
library('brms')
```


# Experiment 1 Cleaning and Analysis
Read in and join raw data with the key
```{r}
# Reads in data files
data = read.csv('/Users/caseyfelton/Desktop/Githubs/syntactic_disjunction_html/Analysis/Data/Real Data/full_collection.csv')

# Factorizes and renames id column
data = data %>% 
  mutate(ID = as.factor(Condition_Item))

# Select just the columns needed for analysis
data = data %>% select(workerid, ID, chance)

# Reads in key file
key = read.csv('/Users/caseyfelton/Desktop/Githubs/syntactic_disjunction_html/Analysis/Resources/new_key.csv')

# Factorizes IS column
# Factorizes and renames id column
key = key %>% 
  mutate(ID = as.factor(Condition_Item))

key = key %>%  select(-Condition_Item)

# Joins key and data
data = left_join(data, key, by = 'ID')

# Remove data from a previous version of the study (10 subjects were run, workerids 119-128) (Additionally, one trial run (wokerid 133) was run on the real data on 11/12, all 100% so it will be excluded by the attention check in the next code chunk.)
data = filter(data, data$workerid != 119 & data$workerid != 120 & data$workerid != 121 & data$workerid != 122 & data$workerid !=  123 & data$workerid != 124 & data$workerid !=  125 & data$workerid !=126 & data$workerid != 127 & data$workerid !=  128)
```


# Data Cleaning
There are a total of 18 attention checking control items, each of which should result in either close to 0% or close to 100% chance ratings from participants who were paying attention. The following code block excludes participants who did not rate at least 17 out of the 18 control items as within 10% of either 0% or 100%, whichever was accurate. 
```{r}
#Filter just the 100% control items
cntr_100 = data %>% filter(Condition == 'And')
#Filter just the 0% control items
cntr_0 = data %>% filter(Condition == 'But_Not')

#Adds a column for accuracy
cntr_100$correct = cntr_100$chance >= 90
cntr_0$correct = cntr_0$chance <= 10

#Combines the items
accuracy_check = rbind(cntr_0, cntr_100)

#Creates a table with the aggregated mean accuracy for each participant
accuracy_table = accuracy_check %>% group_by(workerid) %>% summarise(mean_accuracy = mean(correct))

#Join the accuracy table to the rest of the data
data = left_join(data, accuracy_table, by = 'workerid')

#Filter out participants who got less than 17/18 correct (Starting with 60 real + 1 beta test, the beta and 14 others are excluded, leaving 46)
data = data %>% filter(mean_accuracy > .93)
data = data %>% filter(Group != "filler")
```

# Overview of Analysis
There were a few research questions we most wanted to test in this experiment. First, does ellipsis result in more inclusive readings of disjunctions? Second, is it the ellipsis itself or iconicity that leads to the effect? Lastly, does ellipsis length or the specific constituents being elided impact judgements?

The following code aggregates group means, standard deviations, and standard errors for each item
```{r}
as.factor(data$Condition)
data$Condition = factor(data$Condition, levels=c('C_Proper', 'C_Pronoun', 'VP', 'NP'))

means_contype = data %>% 
  group_by(Condition) %>% 
  summarise(Mean_Chance = mean(chance),
            Standard_Deviation = sd(chance),
            Standard_Error = Standard_Deviation/sqrt(length(unique(data$workerid))))
print(means_contype)
```

The following code summarizes the effect of overall constituent length similarly
```{r}
as.factor(data$Con_Length)
data$Con_Length = factor(data$Con_Length, levels=c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))

means_Length = data %>% 
  group_by(Con_Length) %>% 
  summarise(Mean_Chance = mean(chance),
            Standard_Deviation = sd(chance),
            Standard_Error = Standard_Deviation/sqrt(length(unique(data$workerid))))
print(means_Length)
```
# The following code makes a graphic of the mean inclusivity by disjunct constituent type
```{r}
### Retrieve means and append key
item_means = data %>% 
  group_by(ID) %>% 
  summarise(Mean = mean(chance))
graphdata_1 = left_join(item_means, key, by= 'ID')

### Reorder Factors 
as.factor(graphdata_1$Con_Length)
graphdata_1$Con_Length = factor(graphdata_1$Con_Length, levels=c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
as.factor(graphdata_1$Condition)
graphdata_1$Condition = factor(graphdata_1$Condition, levels=c('C_Proper', 'C_Pronoun', 'VP', 'NP'))

### Rename Conditions
graphdata_1 = graphdata_1 %>% mutate(Condition = fct_recode(Condition, 'Clause with Proper Name' = 'C_Proper'))
graphdata_1 = graphdata_1 %>% mutate(Condition = fct_recode(Condition, 'Clause with Pronoun' = 'C_Pronoun'))
graphdata_1 = graphdata_1 %>% mutate(Condition = fct_recode(Condition, 'Verb Phrase' = 'VP'))
graphdata_1 = graphdata_1 %>% mutate(Condition = fct_recode(Condition, 'Noun Phrase' = 'NP'))

### Plot
g2 = ggplot(aes(Condition, Mean), data = graphdata_1)
g2 = g2 + geom_violin() + geom_point(alpha=0.6) +
  labs(title = 'Inclusivity Ratings by Disjunct Constituent Type', x = 'Constituent Type', y = 'Mean Inclusivity Ratings (%)') + theme_bw()
g2
```
# The following code makes a graphic of the mean inclusivity by constituent length
```{r}
### Plot
g3 = ggplot(aes(Con_Length, Mean), data = graphdata_1)
g3 = g3 + geom_violin() + geom_point(alpha=0.6) +
  labs(title = 'Inclusivity Ratings by Disjunct Constituent Length', x = 'Constituent Length (# of words)', y = 'Mean Inclusivity Ratings (%)') + theme_bw()
g3
```


# The following code creates a combined graphic where each point is the mean inclusivity rating for a specific item x condition pair. The Y axis is the inclusivity, the X axis is the length of the disjoint constituents, and the color fill is the constituent type.
```{r}
### Plot
g1 = ggplot(aes(Con_Length, Mean), data = graphdata_1)
g1 = g1 + geom_point(aes(x = Con_Length, y = Mean, color = Condition)) +
  labs(title = 'Inclusivity Ratings by Disjunct Length and Type', x = 'Disjunct Length', y = 'Mean Inclusivity Ratings (%)', color = 'Disjunct Constituent Type') + theme_bw()
g1
```



This model tests the effect syntactic category and length:
```{r}
data$Con_Length = as.integer(data$Con_Length)
data$Simp_Con = data$Condition
data = data %>% mutate(Simp_Con = fct_recode(Simp_Con, 'C' = 'C_Proper'))
data = data %>% mutate(Simp_Con = fct_recode(Simp_Con, 'C' = 'C_Pronoun'))

model = brm(chance ~ Simp_Con + Con_Length + Simp_Con*Con_Length + (1 + Item|workerid) + (1|Item),
             data = data,
             family = gaussian,
             iter = 4000,
             cores = 4,
             chains = 4,
             warmup = 1000,
             control = list(adapt_delta = 0.99, max_treedepth = 15),
             seed = 4
             )
summary(model)
plot(model)
post_samples = as.data.frame(fixef(model, summary = F))
nrow(filter(post_samples, post_samples$Simp_ConNP > 0))/12000


model_2 = brm(chance ~ Simp_Con + Con_Length + Simp_Con*Con_Length + (1 + Item|workerid) + (1|Item),
             data = data,
             family = gaussian,
             iter = 4000,
             cores = 4,
             chains = 4,
             warmup = 1000,
             control = list(adapt_delta = 0.99, max_treedepth = 15),
             seed = 4
             )
summary(model_2)
plot(model_2)
post_samples_2 = as.data.frame(fixef(model_2, summary = F))
nrow(filter(post_samples_2, post_samples_2$Simp_ConNP > 0))/12000
```
