---
title: "Syntactic Disjunction"
author: "Casey D. Felton"
date: '2023-03-28'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

Load required libraries
```{r, include= FALSE}
library('tidyverse')
library('ggplot2')
library('lme4')
library('lmerTest')
```


# Experiment 1 Cleaning and Analysis
Read in and join raw data with the key
```{r}
# Reads in data files
data = read.csv('/Users/caseyfelton/Desktop/Githubs/syntactic_disjunction_html/Analysis/Data/Beta Data/beta_Sep5.csv')

# Factorizes and renames id column
data = data %>% 
  mutate(ID = as.factor(Condition_Item))

# Select just the columns needed for analysis
data = data %>% select(workerid, ID, chance)

# Reads in key file
key = read.csv('/Users/caseyfelton/Desktop/Githubs/syntactic_disjunction_html/Analysis/Resources/new_key.csv')

# Factorizes IS column
# Factorizes and renames id column
key = key %>% 
  mutate(ID = as.factor(Condition_Item))

key = key %>%  select(-Condition_Item)

# Joins key and data
data = left_join(data, key, by = 'ID')
```


# Data Cleaning
There are a total of 9 attention checking control items, each of which should result in either close to 0% or close to 100% chance ratings from participants who were paying attention. The following code block excludes participants who did not rate at least 5 out of the 6 control items as within 10% of either 0% or 100%, whichever was accurate. 
```{r}
#Filter just the 100% control items
cntr_100 = data %>% filter(Condition == 'And')
#Filter just the 0% control items
cntr_0 = data %>% filter(Condition == 'But_Not')

#Adds a column for accuracy
cntr_100$correct = cntr_100$chance >= 90
cntr_0$correct = cntr_0$chance <= 10

#Combines the items
accuracy_check = rbind(cntr_0, cntr_100)

#Creates a table with the aggregated mean accuracy for each participant
accuracy_table = accuracy_check %>% group_by(workerid) %>% summarise(mean_accuracy = mean(correct))

#Join the accuracy table to the rest of the data
data = left_join(data, accuracy_table, by = 'workerid')

#Filter out participants who got less than 5/6 correct (Starting with 50, 8 are excluded, leaving 42)
data = data %>% filter(mean_accuracy > .95)
data = data %>% filter(Group != "filler")
```

# Overview of Analysis
There were a few research questions we most wanted to test in this experiment. First, does ellipsis result in more inclusive readings of disjunctions? Second, is it the ellipsis itself or iconicity that leads to the effect? Lastly, does ellipsis length or the specific constituents being elided impact judgements?

The following code aggregates group means, standard deviations, and standard errors for each item
```{r}
as.factor(data$Condition)
data$Condition = factor(data$Condition, levels=c('C_Proper', 'C_Pronoun', 'VP', 'NP'))

means_contype = data %>% 
  group_by(Condition) %>% 
  summarise(Mean_Chance = mean(chance),
            Standard_Deviation = sd(chance),
            Standard_Error = Standard_Deviation/sqrt(length(unique(data$workerid))))
print(means_contype)
```

The following code summarizes the effect of overall constituent length similarly
```{r}
as.factor(data$Con_Length)
data$Con_Length = factor(data$Con_Length, levels=c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))

means_Length = data %>% 
  group_by(Con_Length) %>% 
  summarise(Mean_Chance = mean(chance),
            Standard_Deviation = sd(chance),
            Standard_Error = Standard_Deviation/sqrt(length(unique(data$workerid))))
print(means_Length)
```
# The following code makes a graphic of the mean inclusivity by disjunct constituent type
```{r}
### Retrieve means and append key
item_means = data %>% 
  group_by(ID) %>% 
  summarise(Mean = mean(chance))
graphdata_1 = left_join(item_means, key, by= 'ID')

### Reorder Factors 
as.factor(graphdata_1$Con_Length)
graphdata_1$Con_Length = factor(graphdata_1$Con_Length, levels=c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
as.factor(graphdata_1$Condition)
graphdata_1$Condition = factor(graphdata_1$Condition, levels=c('C_Proper', 'C_Pronoun', 'VP', 'NP'))

### Rename Conditions
graphdata_1 = graphdata_1 %>% mutate(Condition = fct_recode(Condition, 'Clause with Proper Name' = 'C_Proper'))
graphdata_1 = graphdata_1 %>% mutate(Condition = fct_recode(Condition, 'Clause with Pronoun' = 'C_Pronoun'))
graphdata_1 = graphdata_1 %>% mutate(Condition = fct_recode(Condition, 'Verb Phrase' = 'VP'))
graphdata_1 = graphdata_1 %>% mutate(Condition = fct_recode(Condition, 'Noun Phrase' = 'NP'))

### Plot
g2 = ggplot(aes(Condition, Mean), data = graphdata_1)
g2 = g2 + geom_violin() + geom_point(alpha=0.6) +
  labs(title = 'Inclusivity Ratings by Disjunct Constituent Type', x = 'Constituent Type', y = 'Mean Inclusivity Ratings (%)') + theme_bw()
g2
```
# The following code makes a graphic of the mean inclusivity by constituent length
```{r}
### Plot
g3 = ggplot(aes(Con_Length, Mean), data = graphdata_1)
g3 = g3 + geom_violin() + geom_point(alpha=0.6) +
  labs(title = 'Inclusivity Ratings by Disjunct Constituent Type', x = 'Constituent Length (# of words)', y = 'Mean Inclusivity Ratings (%)') + theme_bw()
g3
```


# The following code creates a combined graphic where each point is the mean inclusivity rating for a specific item x condition pair. The Y axis is the inclusivity, the X axis is the length of the disjoint constituents, and the color fill is the constituent type.
```{r}
### Plot
g1 = ggplot(aes(Con_Length, Mean), data = graphdata_1)
g1 = g1 + geom_point(aes(x = Con_Length, y = Mean, color = Condition)) +
  labs(title = 'Inclusivity Ratings by Disjunct Length and Type', x = 'Disjunct Length', y = 'Mean Inclusivity Ratings (%)', color = 'Disjunct Constituent Type') + theme_bw()
g1
```



This model tests the effect ellipsis and iconicity:
```{r}
model_1 = lmer(chance ~ Condition + Con_Length + Condition*Con_length + (1 + Item|workerid) + (1|Item), data = data)
summary(model_1)
```
